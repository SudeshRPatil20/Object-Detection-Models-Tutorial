{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12247700,"sourceType":"datasetVersion","datasetId":7717093}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-07T09:16:18.185282Z","iopub.execute_input":"2025-08-07T09:16:18.185518Z","iopub.status.idle":"2025-08-07T09:16:18.189957Z","shell.execute_reply.started":"2025-08-07T09:16:18.185495Z","shell.execute_reply":"2025-08-07T09:16:18.189203Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport shutil\nimport random\n\n# Paths\ninput_base = '/kaggle/input/cloud-types/clouds'\nworking_base = '/kaggle/working/datasets_folder'\n\n# List of cloud categories\ncategories = [\n    'altocumulus', 'altostratus', 'cirrocumulus', 'cirrostratus', 'cirrus',\n    'contrails', 'cumulonimbus', 'cumulus', 'lenticular', 'mammatus',\n    'nimbostratus', 'stratocumulus', 'stratus'\n]\n\n# Ratios for dataset split\ntrain_ratio = 0.7\nval_ratio = 0.15\ntest_ratio = 0.15\n\n# Step 1: Copy original data to writable working directory\nfor category in categories:\n    src_dir = os.path.join(input_base, category)\n    dst_dir = os.path.join(working_base, category)\n    os.makedirs(dst_dir, exist_ok=True)\n\n    for filename in os.listdir(src_dir):\n        src_file = os.path.join(src_dir, filename)\n        dst_file = os.path.join(dst_dir, filename)\n        try:\n            if os.path.getsize(src_file) > 0:  # Skip empty files\n                shutil.copy2(src_file, dst_file)\n        except:\n            continue  # Skip corrupt/unreadable files\n\n# Step 2: Create train/validation/test folders\nfor split in ['train', 'val', 'test']:\n    for category in categories:\n        os.makedirs(os.path.join(working_base, split, category), exist_ok=True)\n\n# Step 3: Split and copy files\nfor category in categories:\n    src_dir = os.path.join(working_base, category)\n    all_files = [f for f in os.listdir(src_dir) if os.path.getsize(os.path.join(src_dir, f)) > 0]\n    random.shuffle(all_files)\n\n    total_files = len(all_files)\n    train_end = int(total_files * train_ratio)\n    val_end = train_end + int(total_files * val_ratio)\n\n    train_files = all_files[:train_end]\n    val_files = all_files[train_end:val_end]\n    test_files = all_files[val_end:]\n\n    # Copy files to respective folders\n    for f in train_files:\n        shutil.copy2(os.path.join(src_dir, f), os.path.join(working_base, 'train', category, f))\n    for f in val_files:\n        shutil.copy2(os.path.join(src_dir, f), os.path.join(working_base, 'val', category, f))\n    for f in test_files:\n        shutil.copy2(os.path.join(src_dir, f), os.path.join(working_base, 'test', category, f))\n\nprint(\"Data split complete. Check /kaggle/working/datasets_folder/\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T18:30:35.111644Z","iopub.execute_input":"2025-09-21T18:30:35.111933Z","iopub.status.idle":"2025-09-21T18:30:36.802198Z","shell.execute_reply.started":"2025-09-21T18:30:35.111909Z","shell.execute_reply":"2025-09-21T18:30:36.801405Z"}},"outputs":[{"name":"stdout","text":"Data split complete. Check /kaggle/working/datasets_folder/\n","output_type":"stream"}],"execution_count":70},{"cell_type":"code","source":"import os\nimport time\nimport io\nimport csv\nimport json\nimport subprocess\nfrom pathlib import Path\nfrom typing import List, Dict, Tuple\n\nimport numpy as np\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, datasets, models\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torch.profiler import profile, ProfilerActivity, record_function, tensorboard_trace_handler\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T18:31:05.320037Z","iopub.execute_input":"2025-09-21T18:31:05.320312Z","iopub.status.idle":"2025-09-21T18:31:05.325304Z","shell.execute_reply.started":"2025-09-21T18:31:05.320293Z","shell.execute_reply":"2025-09-21T18:31:05.324606Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T18:31:06.952161Z","iopub.execute_input":"2025-09-21T18:31:06.952824Z","iopub.status.idle":"2025-09-21T18:31:06.956578Z","shell.execute_reply.started":"2025-09-21T18:31:06.952800Z","shell.execute_reply":"2025-09-21T18:31:06.955916Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"try:\n    import psutil\nexcept Exception:\n    psutil = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T18:31:07.360145Z","iopub.execute_input":"2025-09-21T18:31:07.360422Z","iopub.status.idle":"2025-09-21T18:31:07.364413Z","shell.execute_reply.started":"2025-09-21T18:31:07.360399Z","shell.execute_reply":"2025-09-21T18:31:07.363561Z"}},"outputs":[],"execution_count":73},{"cell_type":"code","source":"DATA_DIR = \"/kaggle/working/datasets_folder\"   \nTRAIN_SUBDIR = \"train\"\nVAL_SUBDIR = \"val\"   \nOUTPUT_DIR = \"results\"\nLOG_DIR = \"logs/tensorboard\"\nPROFILE_DIR = os.path.join(OUTPUT_DIR, \"profiles\")\nMODEL_DIR = os.path.join(OUTPUT_DIR, \"models\")\n\nBATCH_SIZES = [1, 4, 8, 16, 32]\nIMG_SIZE = 224\nNUM_EPOCHS = 1    \nLR = 1e-3\nNUM_WORKERS = 2\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nWARMUP_ITERS = 5\nMEASURE_ITERS = 20      \nPROFILE_STEPS = 6       \nPRINT_EVERY = 20\n\n# dirs\nPath(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\nPath(LOG_DIR).mkdir(parents=True, exist_ok=True)\nPath(PROFILE_DIR).mkdir(parents=True, exist_ok=True)\nPath(MODEL_DIR).mkdir(parents=True, exist_ok=True)\n\n\nmean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\n\ntrain_tf = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std),\n])\n\nval_tf = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std),\n])\n\ntrain_dir = os.path.join(DATA_DIR, TRAIN_SUBDIR)\nval_dir = os.path.join(DATA_DIR, VAL_SUBDIR)\nif not os.path.exists(train_dir) or not os.path.exists(val_dir):\n    raise FileNotFoundError(f\"Expected dataset dirs: {train_dir} and {val_dir}\")\n\ntrain_dataset = datasets.ImageFolder(train_dir, transform=train_tf)\nval_dataset = datasets.ImageFolder(val_dir, transform=val_tf)\nNUM_CLASSES = len(train_dataset.classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T18:31:07.783384Z","iopub.execute_input":"2025-09-21T18:31:07.784004Z","iopub.status.idle":"2025-09-21T18:31:07.797463Z","shell.execute_reply.started":"2025-09-21T18:31:07.783968Z","shell.execute_reply":"2025-09-21T18:31:07.796832Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"def print_dataset_info(ds):\n    print(f\"Num classes: {len(ds.classes)}\")\n    print(\"Classes:\", ds.classes)\n    print(\"Num images:\", len(ds))\n    counts = {c:0 for c in ds.classes}\n    for _, label in ds.samples:\n        counts[ds.classes[label]] += 1\n    print(\"Distribution:\", counts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T18:31:10.304402Z","iopub.execute_input":"2025-09-21T18:31:10.304658Z","iopub.status.idle":"2025-09-21T18:31:10.309007Z","shell.execute_reply.started":"2025-09-21T18:31:10.304639Z","shell.execute_reply":"2025-09-21T18:31:10.308264Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"print(\"Device:\", DEVICE)\nprint_dataset_info(train_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T18:31:10.735165Z","iopub.execute_input":"2025-09-21T18:31:10.735753Z","iopub.status.idle":"2025-09-21T18:31:10.739677Z","shell.execute_reply.started":"2025-09-21T18:31:10.735734Z","shell.execute_reply":"2025-09-21T18:31:10.738937Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\nNum classes: 13\nClasses: ['altocumulus', 'altostratus', 'cirrocumulus', 'cirrostratus', 'cirrus', 'contrails', 'cumulonimbus', 'cumulus', 'lenticular', 'mammatus', 'nimbostratus', 'stratocumulus', 'stratus']\nNum images: 1143\nDistribution: {'altocumulus': 97, 'altostratus': 99, 'cirrocumulus': 99, 'cirrostratus': 100, 'cirrus': 82, 'contrails': 88, 'cumulonimbus': 76, 'cumulus': 86, 'lenticular': 82, 'mammatus': 83, 'nimbostratus': 86, 'stratocumulus': 84, 'stratus': 81}\n","output_type":"stream"}],"execution_count":76},{"cell_type":"code","source":"def system_ram_mb() -> float:\n    if psutil:\n        vm = psutil.virtual_memory()\n        used = (vm.total - vm.available) / (1024**2)\n        return round(used, 2)\n    return -1.0\n\ndef nvidia_smi_query():\n    \"\"\"Return (gpu_util_pct, vram_used_mb) aggregated average across GPUs or -1 if not found.\"\"\"\n    if not torch.cuda.is_available():\n        return -1.0, -1.0\n    try:\n        out = subprocess.check_output([\"nvidia-smi\", \"--query-gpu=utilization.gpu,memory.used\", \"--format=csv,noheader,nounits\"])\n        lines = out.decode().strip().splitlines()\n        # take first GPU\n        util, mem = [float(x.strip()) for x in lines[0].split(\",\")]\n        return util, mem\n    except Exception:\n        return -1.0, -1.0\n\ndef model_size_mb(model: nn.Module) -> float:\n    # serialize to buffer\n    buffer = io.BytesIO()\n    torch.save(model.state_dict(), buffer)\n    size = buffer.getbuffer().nbytes / (1024**2)\n    return round(size, 3)\n\ndef topk_counts(outputs: torch.Tensor, labels: torch.Tensor, k: int=5) -> int:\n    with torch.no_grad():\n        _, idx = outputs.topk(k, 1, True, True)\n        correct = 0\n        for i in range(labels.size(0)):\n            if labels[i].item() in idx[i]:\n                correct += 1\n        return correct\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T18:31:22.052295Z","iopub.execute_input":"2025-09-21T18:31:22.052952Z","iopub.status.idle":"2025-09-21T18:31:22.059672Z","shell.execute_reply.started":"2025-09-21T18:31:22.052929Z","shell.execute_reply":"2025-09-21T18:31:22.059028Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"def make_densenet(num_classes: int, pretrained=True):\n    model = models.densenet121(pretrained=pretrained)\n    num_ftrs = model.classifier.in_features\n    model.classifier = nn.Linear(num_ftrs, num_classes)\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T18:31:24.392275Z","iopub.execute_input":"2025-09-21T18:31:24.392545Z","iopub.status.idle":"2025-09-21T18:31:24.396682Z","shell.execute_reply.started":"2025-09-21T18:31:24.392518Z","shell.execute_reply":"2025-09-21T18:31:24.395905Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"def train_epoch(model, loader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    running_correct = 0\n    total = 0\n    for i, (images, labels) in enumerate(loader, 1):\n        images = images.to(device)\n        labels = labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()*images.size(0)\n        preds = outputs.argmax(dim=1)\n        running_correct += (preds == labels).sum().item()\n        total += images.size(0)\n        if i % PRINT_EVERY == 0:\n            print(f\"  Batch {i} loss={running_loss/total:.4f} acc={running_correct/total:.4f}\")\n    return running_loss/total if total>0 else 0.0, running_correct/total if total>0 else 0.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T18:31:25.575695Z","iopub.execute_input":"2025-09-21T18:31:25.576198Z","iopub.status.idle":"2025-09-21T18:31:25.582036Z","shell.execute_reply.started":"2025-09-21T18:31:25.576172Z","shell.execute_reply":"2025-09-21T18:31:25.581196Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"def evaluate(model, loader, device):\n    model.eval()\n    running_loss = 0.0\n    running_correct = 0\n    top5_correct = 0\n    total = 0\n    criterion = nn.CrossEntropyLoss()\n    with torch.no_grad():\n        for images, labels in loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            running_loss += loss.item()*images.size(0)\n            preds = outputs.argmax(dim=1)\n            running_correct += (preds == labels).sum().item()\n            top5_correct += topk_counts(outputs, labels, k=5)\n            total += images.size(0)\n    if total==0:\n        return 0.0, 0.0, 0.0\n    return running_loss/total, running_correct/total, top5_correct/total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T18:31:27.153355Z","iopub.execute_input":"2025-09-21T18:31:27.153618Z","iopub.status.idle":"2025-09-21T18:31:27.159436Z","shell.execute_reply.started":"2025-09-21T18:31:27.153597Z","shell.execute_reply":"2025-09-21T18:31:27.158687Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"def measure_latency_throughput(model, device, batch_size, img_size, dtype=torch.float32, warmup=5, iters=10):\n    model.eval()\n    dummy = torch.randn(batch_size, 3, img_size, img_size, device=device, dtype=dtype)\n    \n    with torch.no_grad():\n        # --- WRAP IN AUTocast FOR AMP ---\n        if dtype == torch.float16 and device.type == 'cuda':\n            autocast_ctx = autocast\n        else:\n            class DummyCtx:\n                def __enter__(self): return None\n                def __exit__(self, exc_type, exc_val, exc_tb): return False\n            autocast_ctx = DummyCtx\n\n        # Warmup\n        for _ in range(max(1, warmup)):\n            with autocast_ctx():\n                _ = model(dummy)\n\n        # Timing\n        import time\n        start = time.time()\n        for _ in range(iters):\n            with autocast_ctx():\n                _ = model(dummy)\n        if device.type == 'cuda':\n            torch.cuda.synchronize()\n        end = time.time()\n    \n    latency_ms = (end - start) / iters * 1000\n    throughput = batch_size / (latency_ms / 1000)\n    \n    peak_vram = torch.cuda.max_memory_allocated(device) / 1024**2 if device.type=='cuda' else 0\n    return latency_ms, throughput, peak_vram\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T18:33:55.883027Z","iopub.execute_input":"2025-09-21T18:33:55.883791Z","iopub.status.idle":"2025-09-21T18:33:55.890632Z","shell.execute_reply.started":"2025-09-21T18:33:55.883757Z","shell.execute_reply":"2025-09-21T18:33:55.889921Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"def run_profiler(model, loader, logdir_variant):\n    \"\"\"Run a few steps with PyTorch profiler and write TensorBoard traces under logdir_variant.\"\"\"\n    activities = [ProfilerActivity.CPU]\n    if torch.cuda.is_available():\n        activities.append(ProfilerActivity.CUDA)\n    print(\"  Starting profiler write to\", logdir_variant)\n    try:\n        with profile(\n            activities=activities,\n            record_shapes=True,\n            profile_memory=True,\n            with_stack=True,\n            on_trace_ready=tensorboard_trace_handler(logdir_variant),\n        ) as prof:\n            model.eval()\n            it = iter(loader)\n            steps = 0\n            while steps < PROFILE_STEPS:\n                try:\n                    images, labels = next(it)\n                except StopIteration:\n                    break\n                images = images.to(DEVICE) if DEVICE.type=='cuda' else images\n                with record_function(\"model_infer\"):\n                    _ = model(images)\n                prof.step()\n                steps += 1\n        print(f\"  Profiler: wrote {steps} steps to {logdir_variant}\")\n    except Exception as e:\n        print(\"  Profiler failed:\", e)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T18:33:57.674427Z","iopub.execute_input":"2025-09-21T18:33:57.675064Z","iopub.status.idle":"2025-09-21T18:33:57.681272Z","shell.execute_reply.started":"2025-09-21T18:33:57.675025Z","shell.execute_reply":"2025-09-21T18:33:57.680380Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"def apply_dynamic_quantization(model_cpu: nn.Module):\n    \"\"\"Apply dynamic quantization to linear / LSTM layers (works on CPU).\"\"\"\n    model_cpu.eval()\n    q_model = torch.quantization.quantize_dynamic(\n        model_cpu, {nn.Linear}, dtype=torch.qint8\n    )\n    return q_model\n\ndef prepare_torchscript(model, example_shape=(1,3,IMG_SIZE,IMG_SIZE)):\n    model.eval()\n    example = torch.randn(*example_shape).to(DEVICE)\n    with torch.no_grad():\n        scripted = torch.jit.trace(model, example)\n    class Wrapped(nn.Module):\n        def __init__(self, mod):\n            super().__init__()\n            self.mod = mod\n        def forward(self, x):\n            return self.mod(x)\n    return Wrapped(scripted).to(DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T18:33:58.620231Z","iopub.execute_input":"2025-09-21T18:33:58.620922Z","iopub.status.idle":"2025-09-21T18:33:58.626316Z","shell.execute_reply.started":"2025-09-21T18:33:58.620895Z","shell.execute_reply":"2025-09-21T18:33:58.625580Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom torch.cuda.amp import autocast, GradScaler\nimport torch\nimport os\nimport csv\nimport json\n\n\ndef train_epoch_amp(model, loader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    running_correct = 0\n    total = 0\n    scaler = GradScaler()  # local to function\n\n    for images, labels in loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n\n        with autocast():\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        running_loss += loss.item() * images.size(0)\n        preds = outputs.detach().float().argmax(dim=1)  # FP32 for safety\n        running_correct += (preds == labels).sum().item()\n        total += images.size(0)\n\n    avg_loss = running_loss / total if total > 0 else 0.0\n    avg_acc = running_correct / total if total > 0 else 0.0\n    return avg_loss, avg_acc\n\n\ndef main():\n    # Dataloaders\n    ref_batch = max(BATCH_SIZES)\n    train_loader = DataLoader(train_dataset, batch_size=ref_batch, shuffle=True, num_workers=NUM_WORKERS)\n\n    def val_loader_factory(bs):\n        return DataLoader(val_dataset, batch_size=bs, shuffle=False, num_workers=NUM_WORKERS)\n\n    all_results = []\n\n\n    print(\"=== Baseline FP32 ===\")\n    baseline = make_densenet(NUM_CLASSES, pretrained=True).to(DEVICE)\n    baseline_results = benchmark_variant(\"baseline_fp32\", baseline, train_loader, val_loader_factory, BATCH_SIZES, DEVICE, LOG_DIR)\n    all_results.extend(baseline_results)\n\n\n    if DEVICE.type == 'cuda':\n        print(\"=== AMP (mixed precision) ===\")\n        amp_model = make_densenet(NUM_CLASSES, pretrained=True).to(DEVICE)\n\n       \n        global train_epoch\n        orig_train_epoch = train_epoch\n        train_epoch = train_epoch_amp\n\n        amp_results = benchmark_variant(\"amp_fp16\", amp_model, train_loader, val_loader_factory, BATCH_SIZES, DEVICE, LOG_DIR)\n        all_results.extend(amp_results)\n\n        \n        train_epoch = orig_train_epoch\n    else:\n        print(\"GPU not available: skipping AMP variant\")\n\n\n    try:\n        print(\"=== TorchScript variant ===\")\n        ts_model = make_densenet(NUM_CLASSES, pretrained=True).to(DEVICE)\n        ts_wrapped = prepare_torchscript(ts_model)\n        ts_results = benchmark_variant(\"torchscript\", ts_wrapped, train_loader, val_loader_factory, BATCH_SIZES, DEVICE, LOG_DIR)\n        all_results.extend(ts_results)\n    except Exception as e:\n        print(\"TorchScript creation failed:\", e)\n\n\n    try:\n        print(\"=== Dynamic Quantization (CPU) ===\")\n        cpu_model = make_densenet(NUM_CLASSES, pretrained=True).to('cpu')\n        q_model = apply_dynamic_quantization(cpu_model)\n        cpu_device = torch.device('cpu')\n        train_loader_cpu = DataLoader(train_dataset, batch_size=max(1, min(8, ref_batch)), shuffle=True, num_workers=NUM_WORKERS)\n        def val_loader_factory_cpu(bs):\n            return DataLoader(val_dataset, batch_size=bs, shuffle=False, num_workers=NUM_WORKERS)\n        q_results = benchmark_variant(\"dynamic_quant_cpu\", q_model, train_loader_cpu, val_loader_factory_cpu, [1,4,8], cpu_device, LOG_DIR)\n        all_results.extend(q_results)\n    except Exception as e:\n        print(\"Dynamic quantization failed:\", e)\n\n\n    csv_path = os.path.join(OUTPUT_DIR, \"benchmark_results.csv\")\n    fieldnames = [\"model_variant\",\"batch_size\",\"device\",\"ram_usage_mb\",\"vram_usage_mb\",\"cpu_utilization_pct\",\"gpu_utilization_pct\",\"latency_ms\",\"throughput_samples_sec\",\"accuracy_top1\",\"accuracy_top5\",\"model_size_mb\",\"optimization_technique\"]\n    with open(csv_path, \"w\", newline=\"\") as f:\n        writer = csv.DictWriter(f, fieldnames=fieldnames)\n        writer.writeheader()\n        for r in all_results:\n            out = {k: r.get(k, \"\") for k in fieldnames}\n            writer.writerow(out)\n\n    print(\"Saved CSV:\", csv_path)\n    print(\"Models saved in:\", MODEL_DIR)\n    print(\"TensorBoard logs in:\", LOG_DIR)\n    print(\"Profiler traces in:\", PROFILE_DIR)\n\n\n    print(\"\\nSummary:\")\n    for r in all_results:\n        print(r)\n\n\n    with open(os.path.join(OUTPUT_DIR, \"benchmark_results.json\"), \"w\") as f:\n        json.dump(all_results, f, indent=2)\n\n    print(\"All done.\")\n\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T18:34:00.921031Z","iopub.execute_input":"2025-09-21T18:34:00.921312Z"}},"outputs":[{"name":"stdout","text":"=== Baseline FP32 ===\n[baseline_fp32] Training epoch 1/1\n[baseline_fp32] Train loss 2.0158 acc 0.3185 | Val loss 1.9515 top1 0.4434 top5 0.8139\n  Saved best model for baseline_fp32\n  Starting profiler write to logs/tensorboard/baseline_fp32\n  Profiler: wrote 6 steps to logs/tensorboard/baseline_fp32\n[baseline_fp32] bs=1 top1=0.4434 top5=0.8139 lat=20.490002632141113ms thr=48.804288508551764 samples/s peak_vram=2955.9677734375 MB\n[baseline_fp32] bs=4 top1=0.4434 top5=0.8139 lat=20.9658145904541ms thr=190.78676779967478 samples/s peak_vram=2955.9677734375 MB\n[baseline_fp32] bs=8 top1=0.4434 top5=0.8139 lat=25.339221954345703ms thr=315.7160868796128 samples/s peak_vram=2955.9677734375 MB\n[baseline_fp32] bs=16 top1=0.4434 top5=0.8139 lat=56.996703147888184ms thr=280.71799097721714 samples/s peak_vram=2955.9677734375 MB\n[baseline_fp32] bs=32 top1=0.4434 top5=0.8139 lat=112.72008419036865ms thr=283.8890711433148 samples/s peak_vram=2955.9677734375 MB\n=== AMP (mixed precision) ===\n[amp_fp16] Training epoch 1/1\n[amp_fp16] Train loss 1.8833 acc 0.3788 | Val loss 2.1424 top1 0.3923 top5 0.8522\n  Saved best model for amp_fp16\n  Starting profiler write to logs/tensorboard/amp_fp16\n  Profiler: wrote 6 steps to logs/tensorboard/amp_fp16\n[amp_fp16] bs=1 top1=0.3923 top5=0.8522 lat=26.237964630126953ms thr=38.112712403452974 samples/s peak_vram=2959.78515625 MB\n[amp_fp16] bs=4 top1=0.3923 top5=0.8522 lat=25.712203979492188ms thr=155.56814978561783 samples/s peak_vram=2959.78515625 MB\n[amp_fp16] bs=8 top1=0.3923 top5=0.8522 lat=26.498937606811523ms thr=301.89889567284416 samples/s peak_vram=2959.78515625 MB\n[amp_fp16] bs=16 top1=0.3923 top5=0.8522 lat=26.34432315826416ms thr=607.3414717804519 samples/s peak_vram=2959.78515625 MB\n[amp_fp16] bs=32 top1=0.3923 top5=0.8522 lat=56.46347999572754ms thr=566.7380048559063 samples/s peak_vram=2959.78515625 MB\n=== TorchScript variant ===\n[torchscript] Training epoch 1/1\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T18:27:28.755627Z","iopub.execute_input":"2025-09-21T18:27:28.755886Z","iopub.status.idle":"2025-09-21T18:27:28.988471Z","shell.execute_reply.started":"2025-09-21T18:27:28.755866Z","shell.execute_reply":"2025-09-21T18:27:28.987659Z"}},"outputs":[{"name":"stdout","text":"=== Baseline FP32 ===\n[baseline_fp32] Training epoch 1/1\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3832242952.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_36/1165293008.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=== Baseline FP32 ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mbaseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_densenet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mbaseline_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbenchmark_variant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"baseline_fp32\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader_factory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOG_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mall_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/3104340544.py\u001b[0m in \u001b[0;36mbenchmark_variant\u001b[0;34m(name, model, train_loader, val_loader_fn, batch_sizes, device, writer_root)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[{name}] Training epoch {epoch+1}/{NUM_EPOCHS}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtacc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mvloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvacc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvtop5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[{name}] Train loss {tloss:.4f} acc {tacc:.4f} | Val loss {vloss:.4f} top1 {vacc:.4f} top5 {vtop5:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: main.<locals>.train_epoch_amp() missing 1 required positional argument: 'scaler'"],"ename":"TypeError","evalue":"main.<locals>.train_epoch_amp() missing 1 required positional argument: 'scaler'","output_type":"error"}],"execution_count":66},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# If  you want to use DenseNet for Transferlearning use below code","metadata":{}},{"cell_type":"code","source":"# data_dir=\"/kaggle/working/datasets_folder\"\n# train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform)\n# val_dataset = datasets.ImageFolder(os.path.join(data_dir, 'test'), transform=transform)\n\n# train_loader=torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n# val_loader=torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T17:35:06.160788Z","iopub.execute_input":"2025-09-21T17:35:06.161079Z","iopub.status.idle":"2025-09-21T17:35:06.169612Z","shell.execute_reply.started":"2025-09-21T17:35:06.161057Z","shell.execute_reply":"2025-09-21T17:35:06.169110Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# def get_dataset_info(datasets):\n#     print(f\"Number of Classes: {len(datasets.classes)}\")\n#     print(f\"Class name:  {datasets.classes}\")\n#     print(f\"Number of Images: {len(datasets)}\")\n#     class_count={cls : 0 for cls in datasets.classes}\n#     for _, label in datasets.samples:\n#         # class_count[datasets.classes[label]] += 1\n#     print(\"Class distribution\")\n#     for cls, count in class_count.items():\n#         print(f\"{cls} : {count}\")\n# print(\"Training data info:\")\n# get_dataset_info(train_dataset)\n# print(\"Testting data info:\")\n# get_dataset_info(val_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T17:35:06.874625Z","iopub.execute_input":"2025-09-21T17:35:06.875298Z","iopub.status.idle":"2025-09-21T17:35:06.881048Z","shell.execute_reply.started":"2025-09-21T17:35:06.875274Z","shell.execute_reply":"2025-09-21T17:35:06.880319Z"}},"outputs":[{"name":"stdout","text":"Training data info:\nNumber of Classes: 13\nClass name:  ['altocumulus', 'altostratus', 'cirrocumulus', 'cirrostratus', 'cirrus', 'contrails', 'cumulonimbus', 'cumulus', 'lenticular', 'mammatus', 'nimbostratus', 'stratocumulus', 'stratus']\nNumber of Images: 1048\nClass distribution\naltocumulus : 86\naltostratus : 92\ncirrocumulus : 89\ncirrostratus : 94\ncirrus : 76\ncontrails : 77\ncumulonimbus : 70\ncumulus : 79\nlenticular : 76\nmammatus : 76\nnimbostratus : 81\nstratocumulus : 76\nstratus : 76\nTestting data info:\nNumber of Classes: 13\nClass name:  ['altocumulus', 'altostratus', 'cirrocumulus', 'cirrostratus', 'cirrus', 'contrails', 'cumulonimbus', 'cumulus', 'lenticular', 'mammatus', 'nimbostratus', 'stratocumulus', 'stratus']\nNumber of Images: 337\nClass distribution\naltocumulus : 28\naltostratus : 30\ncirrocumulus : 26\ncirrostratus : 28\ncirrus : 25\ncontrails : 26\ncumulonimbus : 25\ncumulus : 25\nlenticular : 24\nmammatus : 26\nnimbostratus : 25\nstratocumulus : 24\nstratus : 25\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# model =models.densenet121(pretrained=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T17:35:09.809153Z","iopub.execute_input":"2025-09-21T17:35:09.809418Z","iopub.status.idle":"2025-09-21T17:35:10.007039Z","shell.execute_reply.started":"2025-09-21T17:35:09.809397Z","shell.execute_reply":"2025-09-21T17:35:10.006470Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n# num_ftrs=model.classifier.in_features\n# model.fc = nn.Linear(num_ftrs, len(train_dataset.classes))\n# model = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T17:35:11.299728Z","iopub.execute_input":"2025-09-21T17:35:11.300269Z","iopub.status.idle":"2025-09-21T17:35:11.332465Z","shell.execute_reply.started":"2025-09-21T17:35:11.300245Z","shell.execute_reply":"2025-09-21T17:35:11.331920Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# criterion = nn.CrossEntropyLoss()\n# optimizer = optim.Adam(model.fc.parameters(), lr=0.001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T17:35:17.584902Z","iopub.execute_input":"2025-09-21T17:35:17.585511Z","iopub.status.idle":"2025-09-21T17:35:17.589928Z","shell.execute_reply.started":"2025-09-21T17:35:17.585478Z","shell.execute_reply":"2025-09-21T17:35:17.589213Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# def train(model, train_loader, criterion, optimizer, epoches=10):\n#     model.train()\n#     start_time=time.time()\n#     for epoch in range(epoches):\n#         running_loss=0.0\n#         correct=0\n#         total=0\n#         for images, labels in train_loader:\n#             images, labels = images.to(device), labels.to(device)\n#             optimizer.zero_grad()\n#             outputs = model(images)\n#             loss = criterion(outputs, labels)\n#             loss.backward()\n#             optimizer.step()\n\n#             running_loss += loss.item()\n#             _, pedicted=outputs.max(1)\n#             total += labels.size(0)\n#             correct += pedicted.eq(labels).sum().item()\n#         print(f\"Epochs [{epoch +1}/{epoches}], loss: {running_loss / len(train_loader):.4f}, Accuracy : {100 * correct/total}\")\n#         end_time = time.time()\n#         print(f\"Total Training Time: {end_time - start_time:.2f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T17:35:19.022847Z","iopub.execute_input":"2025-09-21T17:35:19.023136Z","iopub.status.idle":"2025-09-21T17:35:19.028841Z","shell.execute_reply.started":"2025-09-21T17:35:19.023113Z","shell.execute_reply":"2025-09-21T17:35:19.028223Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# def evalution(model, val_loader, criterion):\n#     model.eval()\n#     correct =0\n#     total = 0\n#     val_loss = 0.0\n#     with torch.no_grad():\n#         for images, label in val_loader:\n#             images, labels = images.to(device), labels.to(device)\n#             outputs = model(images)\n#             loss =criterion(outputs, labels)\n#             val_loss += loss.item()\n#             _, predict = outputs.max(1)\n#             total += labels.size(0)\n#             correct += predict.eq(labels).sum().item()\n#     print(f\"Validation : {val_loss/ len(val_loader):.4f}, Accuracy : {100 * correct/total:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T17:35:20.750724Z","iopub.execute_input":"2025-09-21T17:35:20.751259Z","iopub.status.idle":"2025-09-21T17:35:20.756210Z","shell.execute_reply.started":"2025-09-21T17:35:20.751233Z","shell.execute_reply":"2025-09-21T17:35:20.755375Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# def inference(model, image_path, transforms):\n#     model.eval()\n#     image=Image.open(image_path)\n#     image=transforms(image).unsqueeze(0).to(device)\n#     with torch.no_grad():\n#         output = model(image)\n#         _, predict=torch.max(output, 1)\n#     class_name = train_dataset.classes[predict.item()]\n#     print(f\"Predicted class: {class_name}\")\n#     return class_name\n\n# def vitualizing(model, val_loader, transform):\n#     model.eval()\n#     images, labels = next(iter(val_loader))\n#     images, labels = images.to(device), labels.to(device)\n#     with torch.no_grad():\n#         outputs = model(images)\n#         _, predict = torch.max(outputs, 1)\n#     fig = plt.figure(figsize=(10, 10))\n#     for i in range(9):\n#         ax = fig.add_subplot(3, 3, i+1, xtricks=[], ytricks=[])\n#         img= images[i].cpu().numpy().transpose((1, 2, 0))\n#         img= img * np.array([0.299, 0.244, 0.255]) + np.array([0.485, 0.456, 0.406])\n#         img= np.clip(img, 0, 1)\n#         ax.imshow(img)\n#         ax.set_title(f\"Pred: {train_dataset.classes[preds[i].item()]}\")\n#     plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T17:35:27.946517Z","iopub.execute_input":"2025-09-21T17:35:27.946798Z","iopub.status.idle":"2025-09-21T17:35:27.953399Z","shell.execute_reply.started":"2025-09-21T17:35:27.946775Z","shell.execute_reply":"2025-09-21T17:35:27.952728Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"%load_ext tensorboard\n%tensorboard --logdir logs/tensorboard","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T17:53:32.056513Z","iopub.execute_input":"2025-09-21T17:53:32.056801Z","iopub.status.idle":"2025-09-21T17:53:50.625581Z","shell.execute_reply.started":"2025-09-21T17:53:32.056774Z","shell.execute_reply":"2025-09-21T17:53:50.624928Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n        (async () => {\n            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n            url.searchParams.set('tensorboardColab', 'true');\n            const iframe = document.createElement('iframe');\n            iframe.src = url;\n            iframe.setAttribute('width', '100%');\n            iframe.setAttribute('height', '800');\n            iframe.setAttribute('frameborder', 0);\n            document.body.appendChild(iframe);\n        })();\n    "},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}